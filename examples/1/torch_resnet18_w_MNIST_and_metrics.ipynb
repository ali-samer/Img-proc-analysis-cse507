{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-08-29T05:55:32.149668Z",
     "start_time": "2024-08-29T05:55:32.131133Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[5], line 6\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01moptim\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01moptim\u001B[39;00m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdata\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m DataLoader\n\u001B[0;32m----> 6\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msklearn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmetrics\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m precision_recall_fscore_support, confusion_matrix\n\u001B[1;32m      7\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtime\u001B[39;00m\n\u001B[1;32m      8\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mpd\u001B[39;00m\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms, models\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import precision_recall_fscore_support, confusion_matrix\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "# Check if MPS (Metal Performance Shaders) is available and set the device accordingly\n",
    "device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# MNIST dataset\n",
    "train_data = datasets.MNIST(root='data', train=True, transform=transforms.ToTensor(), download=True)\n",
    "test_data = datasets.MNIST(root='data', train=False, transform=transforms.ToTensor())\n",
    "\n",
    "# Data loaders with minimal workers initially; adjust workers gradually\n",
    "loaders = {\n",
    "    'train': DataLoader(train_data, batch_size=256, shuffle=True, num_workers=0, pin_memory=True),\n",
    "    'test': DataLoader(test_data, batch_size=256, shuffle=False, num_workers=0, pin_memory=True),\n",
    "}\n",
    "\n",
    "# Load ResNet18 model without using deprecated 'pretrained' parameter\n",
    "resnet18 = models.resnet18(weights=None)  # Use weights=None instead of pretrained=False\n",
    "\n",
    "# Modify the first convolutional layer to accept grayscale images\n",
    "resnet18.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "\n",
    "# Modify the output layer to match the number of classes in MNIST\n",
    "resnet18.fc = nn.Linear(resnet18.fc.in_features, 10)\n",
    "\n",
    "# Move the model to the device\n",
    "resnet18 = resnet18.to(device)\n",
    "\n",
    "# Loss and optimizer with learning rate adjustment\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(resnet18.parameters(), lr=0.001)\n",
    "\n",
    "# Training function\n",
    "def train(num_epochs, model, loaders):\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        # Training phase\n",
    "        for images, labels in loaders['train']:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = loss_func(outputs, labels)\n",
    "\n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        train_loss = running_loss / len(loaders['train'])\n",
    "        train_accuracy = 100 * correct / total\n",
    "\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%')\n",
    "\n",
    "# Testing function with additional metrics\n",
    "def test(model):\n",
    "    model.eval()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    start_time = time.time()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loaders['test']:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "            y_pred.extend(predicted.cpu().numpy())\n",
    "\n",
    "    # Calculate additional metrics\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='weighted')\n",
    "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "    inference_time = time.time() - start_time\n",
    "    accuracy = sum([y_pred[i] == y_true[i] for i in range(len(y_true))]) / len(y_true) * 100\n",
    "\n",
    "    # Save metrics to a file\n",
    "    metrics = {\n",
    "        'Accuracy': [accuracy],\n",
    "        'Precision': [precision],\n",
    "        'Recall': [recall],\n",
    "        'F1-Score': [f1],\n",
    "        'Inference Time (s)': [inference_time]\n",
    "    }\n",
    "    metrics_df = pd.DataFrame(metrics)\n",
    "    metrics_df.to_csv('model_metrics.csv', index=False)\n",
    "\n",
    "    print(f'Test Accuracy: {accuracy:.2f}%')\n",
    "    print(f'Precision: {precision:.2f}, Recall: {recall:.2f}, F1-Score: {f1:.2f}')\n",
    "    print(f'Inference Time: {inference_time:.4f} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "train(num_epochs, resnet18, loaders)\n",
    "test(resnet18)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
